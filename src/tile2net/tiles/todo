with logging_redirect_tqdm():
    for i, (input_images, labels, img_names, scale_float) in enumerate(tqdm(loader)):
        if i % 20 == 0:
            logger.debug(f'Inference [Iter: {i + 1} / {len(loader)}]')

Tiles

SourceTiles
    - stitch to inference tiles aggregates source tiles
SegTiles
    - stitch to network tiles aggregates inference tiles
    - does not write polygons
NetworkTiles
    - generates polygons for each network tile
    - from polygons creates network tiles
    - each tile is a separate multiprocessing worker

source -> inference -> network

SourceTiles.stitch() -> SegTiles
SegTiles.stitch() -> NetworkTiles

pad.

InTiles.stitch() -> SegTiles
SegTiles.stitch() -> VecTiles

previously, mosaic.xtile and mosaic.ytile were easy because they were 1-to-1 mappings and therefore columns
now, each xtile and ytile can belong to two mosaics

can't use mosaic(frame) because we need to first access lengt,


pred.xtile
out.xtile

padded inherits from
each tile subclass should get its own self.static so it can get self.static.black

predict.py
mask2poly.py

minibatch.py

todo: segtiles.stitch() -> vectiles requires padding intiles once more

intiles.stitch() -> intiles
segtiles.stitch() -> intiles

add cfg.stitch.dimension to cfg

segtiles.predict
.vectiles.vectorize

if intiles:
    dimension is from sample

Tile descriptor has possibly bug if it's accessed for another class while in it
return a copy

predtiles stitches when files is accessed

1   2   4   8   16
3   4   6   10  18

set_segmentation should by default set dimension to 1024 from cfg
set_vectorization should determine from memory

intiles.file.static

segtiles.file.in
segtiles.file.prediction
segtiles.file.mask

vectiles.file.polygon
vectiles.file.network

todo: use groupby during prediction instead of the esoteric cached iterators
we need a "trial" loader to instantiate all the file columns once

if intiles.download:
    ...

with self.download:
    ...

with self.stitch:
    ...


We can use something like the majority vote + confidence mask to force the labels of the pixels with low confidence into the same label as their neighbors starting from like 50 pixels away from the edge

from_slice

downscale to segtile.scale
[x-1, y-1, x+1, y+1]

frame.corners(scale=segtile.scale)

we must figure out how to pad

infiles.padded
scales to largest, adds padding=1 using corners, scales back

infiles padded with segtiles.scale
segtiles padded with segtiles.scale

for broadcasting:

vectiles.corners.to_scale(segtiles.scale)

so we need:
    corners.ntiles -> corners.tile.area
    corners.to_scale(scale)

corners.to_tiles()

check if polygon simplification is a necessary step

lines.explode()
